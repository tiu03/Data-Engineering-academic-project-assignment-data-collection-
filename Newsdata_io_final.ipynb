{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5366766-4d63-4bf5-b3ef-04115f2b1cfa",
   "metadata": {},
   "source": [
    "# 1.0 Data Collection (Web Crawling)\n",
    "\n",
    "###### Author: Terence Tiu Chuan Jie \n",
    "###### Last Edited:9/4/2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff32082-67ec-483f-9d8d-c91eb971bcbf",
   "metadata": {},
   "source": [
    "## 1.Newsdata io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253f3d89-2c54-4b6e-9065-3748ad22679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/18 14:50:23 WARN Utils: Your hostname, tiu. resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/18 14:50:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/18 14:50:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'/home/student/data_collected')\n",
    "\n",
    "\n",
    "from newsdataapi import NewsDataApiClient\n",
    "import pickle\n",
    "import csv  \n",
    "\n",
    "spark = SparkSession.builder.appName('Newsdata io').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2f31ed-1409-4359-b4bc-dc2a40ae4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api = NewsDataApiClient(apikey=\"pub_74815e364b4e931611590c50e5c72985ca80a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9def5a-3fca-48fe-be2b-7035a45b3be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29599/2805961141.py:15: DeprecationWarning: This method is deprecated and will be removed in upcoming updates, Instead use latest_api()\n",
      "  response = self.api.news_api(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {'status': 'error', 'results': {'message': 'You exceeded your assigned API credits, please check your plan and billing details.', 'code': 'ApiLimitExceeded'}}\n",
      "Total articles retrieved: 190\n",
      "News 0: {'article_id': '7cf5fadd91226f2920449067099412b0', 'title': 'Public Safety Logs — Monday, April 7, 2025', 'link': 'https://www.romesentinel.com/news/public-safety/public-safety-logs-monday-april-7-2025/article_fe6ead05-7304-4aa5-bc11-ba6926b5a761.html', 'keywords': None, 'creator': None, 'description': 'Rome Fire Department log', 'content': 'ONLY AVAILABLE IN PAID PLANS', 'pubDate': '2025-04-09 02:00:00', 'pubDateTZ': 'UTC', 'image_url': None, 'video_url': None, 'source_id': 'romesentinel', 'source_name': 'Romesentinel', 'source_priority': 38985, 'source_url': 'https://www.romesentinel.com', 'source_icon': 'https://i.bytvi.com/domain_icons/romesentinel.jpg', 'language': 'english', 'country': ['united states of america'], 'category': ['crime'], 'sentiment': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'sentiment_stats': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_tag': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_region': 'ONLY AVAILABLE IN CORPORATE PLANS', 'ai_org': 'ONLY AVAILABLE IN CORPORATE PLANS', 'duplicate': False}\n",
      "News 1: {'article_id': 'e13fe43d5a15ad308d51141e5185fd8c', 'title': 'Bridgton man charged with threatening to ‘shoot’ Trump', 'link': 'https://www.sunjournal.com/2025/04/08/bridgton-man-charged-with-threatening-to-shoot-trump/', 'keywords': ['maine crime'], 'creator': None, 'description': 'The man allegedly told an undercover Secret Service agent that he planned to kill the president.', 'content': 'ONLY AVAILABLE IN PAID PLANS', 'pubDate': '2025-04-09 01:25:55', 'pubDateTZ': 'UTC', 'image_url': None, 'video_url': None, 'source_id': 'sunjournal', 'source_name': 'Lewiston Sun Journal', 'source_priority': 12472, 'source_url': 'https://www.sunjournal.com', 'source_icon': 'https://i.bytvi.com/domain_icons/sunjournal.jpg', 'language': 'english', 'country': ['united states of america'], 'category': ['crime'], 'sentiment': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'sentiment_stats': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_tag': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_region': 'ONLY AVAILABLE IN CORPORATE PLANS', 'ai_org': 'ONLY AVAILABLE IN CORPORATE PLANS', 'duplicate': True}\n",
      "News 2: {'article_id': '30676a15f69bd19d54ea1d1f6db7357a', 'title': 'Bridgton man charged with threatening to ‘shoot’ Trump', 'link': 'https://www.pressherald.com/2025/04/08/bridgton-man-charged-with-threatening-to-shoot-trump/', 'keywords': ['cops &amp; courts'], 'creator': None, 'description': 'The man allegedly told an undercover Secret Service agent that he planned to kill the president.', 'content': 'ONLY AVAILABLE IN PAID PLANS', 'pubDate': '2025-04-09 01:25:55', 'pubDateTZ': 'UTC', 'image_url': None, 'video_url': None, 'source_id': 'pressherald', 'source_name': 'The Portland Press Herald', 'source_priority': 6760, 'source_url': 'https://www.pressherald.com', 'source_icon': 'https://i.bytvi.com/domain_icons/pressherald.png', 'language': 'english', 'country': ['united states of america'], 'category': ['crime'], 'sentiment': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'sentiment_stats': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_tag': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_region': 'ONLY AVAILABLE IN CORPORATE PLANS', 'ai_org': 'ONLY AVAILABLE IN CORPORATE PLANS', 'duplicate': False}\n",
      "News 3: {'article_id': 'b41d24167d1d07fde3939216dda18e79', 'title': 'Woman stabbed in the neck inside Manhattan homeless shelter', 'link': 'https://www.nydailynews.com/2025/04/08/woman-stabbed-in-the-neck-inside-manhattan-homeless-shelter/', 'keywords': ['nyc crime', 'local news', 'news', 'latest headlines', 'crime and public safety'], 'creator': ['Nicholas Williams'], 'description': 'The 41-year-old victim started arguing with her assailant around 1:59 p.m. at the Bowery Hanbee Hotel on Grand St. and Bowery in Chinatown. After the attack, police were called and the victim, who had a stab wound to her neck, was rushed by EMS to Bellevue Hospital, where she was in stable condition.', 'content': 'ONLY AVAILABLE IN PAID PLANS', 'pubDate': '2025-04-09 00:56:14', 'pubDateTZ': 'UTC', 'image_url': 'https://www.nydailynews.com/wp-content/uploads/migration/2023/01/03/OBBVSKLCY5HTXE6SNDAR2JICZM.jpg?strip=all&w=1400px', 'video_url': None, 'source_id': 'nydailynews', 'source_name': 'New York Daily News', 'source_priority': 1670, 'source_url': 'https://www.nydailynews.com', 'source_icon': 'https://i.bytvi.com/domain_icons/nydailynews.jpg', 'language': 'english', 'country': ['united states of america'], 'category': ['crime'], 'sentiment': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'sentiment_stats': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_tag': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_region': 'ONLY AVAILABLE IN CORPORATE PLANS', 'ai_org': 'ONLY AVAILABLE IN CORPORATE PLANS', 'duplicate': False}\n",
      "News 4: {'article_id': '5b8bf7550789bb4d06548bfbcf3d4e23', 'title': 'Police Logs 4/9/25', 'link': 'https://itemlive.com/2025/04/08/police-logs-4-9-25/', 'keywords': ['police logs', 'police/fire', 'police departments', 'crime'], 'creator': ['Daily Item StaffDaily Item StaffDaily Item Staff'], 'description': 'Daily Item StaffAll address information, particularly arrests, reflects police records. In the event of a perceived inaccuracy, it is the sole responsibility of the concerned party to contact the relevant police department and have the department issue a notice of correction to The Daily Item. LYNN Arrests Jayron Lucas Chajil, 30, of Western Avenue, was arrested at [...]The post Police Logs 4/9/25 appeared first on Itemlive.', 'content': 'ONLY AVAILABLE IN PAID PLANS', 'pubDate': '2025-04-09 00:50:28', 'pubDateTZ': 'UTC', 'image_url': 'https://itemlive.com/wp-content/uploads/2024/07/Police-Lights-Log-e1535672772133-500x434-1-e1712842409371-1.jpg', 'video_url': None, 'source_id': 'itemlive', 'source_name': 'Itemlive', 'source_priority': 27667, 'source_url': 'https://itemlive.com', 'source_icon': 'https://i.bytvi.com/domain_icons/itemlive.png', 'language': 'english', 'country': ['united states of america'], 'category': ['crime'], 'sentiment': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'sentiment_stats': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_tag': 'ONLY AVAILABLE IN PROFESSIONAL AND CORPORATE PLANS', 'ai_region': 'ONLY AVAILABLE IN CORPORATE PLANS', 'ai_org': 'ONLY AVAILABLE IN CORPORATE PLANS', 'duplicate': False}\n",
      "All keys found in articles: {'title', 'description', 'duplicate', 'image_url', 'language', 'ai_region', 'country', 'sentiment', 'category', 'source_priority', 'video_url', 'pubDateTZ', 'creator', 'link', 'source_icon', 'content', 'source_name', 'ai_tag', 'article_id', 'keywords', 'source_url', 'pubDate', 'sentiment_stats', 'source_id', 'ai_org'}\n",
      "Exported 190 articles to newsdata_io_9_4_test.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "class NewsFetcher:\n",
    "    def __init__(self, api, country='us', category='crime', language='en'):\n",
    "        self.api = api\n",
    "        self.country = country\n",
    "        self.category = category\n",
    "        self.language = language\n",
    "        self.news_list = []\n",
    "\n",
    "    def fetch_all_news(self):\n",
    "        page = None\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.api.news_api(\n",
    "                    country=self.country,\n",
    "                    category=self.category,\n",
    "                    language=self.language,\n",
    "                    page=page\n",
    "                )\n",
    "                news = response.get('results', [])\n",
    "                self.news_list.extend(news)\n",
    "\n",
    "                page = response.get('nextPage', None)\n",
    "                if not page:\n",
    "                    print(\"No more pages available.\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                break\n",
    "\n",
    "    def get_news(self):\n",
    "        return self.news_list\n",
    "\n",
    "\n",
    "class NewsAnalyzer:\n",
    "    def __init__(self, news_list):\n",
    "        self.news_list = news_list\n",
    "\n",
    "    def display_sample_news(self, count=5):\n",
    "        for i, news in enumerate(self.news_list[:count]):\n",
    "            print(f\"News {i}: {news}\")\n",
    "\n",
    "    def get_all_keys(self):\n",
    "        all_keys = set()\n",
    "        for news in self.news_list:\n",
    "            all_keys.update(news.keys())\n",
    "        return all_keys\n",
    "\n",
    "\n",
    "class NewsExporter:\n",
    "    def __init__(self, news_list, all_keys):\n",
    "        self.news_list = news_list\n",
    "        self.all_keys = list(all_keys)\n",
    "\n",
    "    def export_to_csv(self, filename='newsdata_io_14_4_test.csv'):\n",
    "        try:\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=self.all_keys)\n",
    "                writer.writeheader()\n",
    "                for news in self.news_list:\n",
    "                    writer.writerow(news)\n",
    "            print(f\"Exported {len(self.news_list)} articles to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write CSV: {e}\")\n",
    "\n",
    "\n",
    "# === Usage ===\n",
    "# `api` is already defined and connected\n",
    "\n",
    "fetcher = NewsFetcher(api)\n",
    "fetcher.fetch_all_news()\n",
    "\n",
    "news_list = fetcher.get_news()\n",
    "print(f\"Total articles retrieved: {len(news_list)}\")\n",
    "\n",
    "analyzer = NewsAnalyzer(news_list)\n",
    "analyzer.display_sample_news()\n",
    "all_keys = analyzer.get_all_keys()\n",
    "print(\"All keys found in articles:\", all_keys)\n",
    "\n",
    "exporter = NewsExporter(news_list, all_keys)\n",
    "exporter.export_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822ed761-d5e2-4902-92ba-df68340598c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7ea40-a835-42c3-8bb8-6d58bab9e212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afb50b-23b5-4855-8cd9-ebdad8c4500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## if u wanna use for pre- preprocessing for here some sample ideal \n",
    "# import json\n",
    "\n",
    "# for news in news_list:\n",
    "#     for key, value in news.items():\n",
    "#         if isinstance(value, list):\n",
    "#             news[key] = ', '.join(value) if value else None  # Convert list to string\n",
    "#         elif isinstance(value, dict):\n",
    "#             news[key] = json.dumps(value)  # Convert dict to JSON string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216145d9-a6d9-4c62-98b6-5e735b828989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_keys = set()\n",
    "# for news in news_list:\n",
    "#     all_keys.update(news.keys())\n",
    "\n",
    "# for news in news_list:\n",
    "#     for key in all_keys:\n",
    "#         if key not in news:\n",
    "#             news[key] = None  # Assign None to missing fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30741d4-b3cb-4748-aac4-86d2cbec9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, StringType, BooleanType\n",
    "\n",
    "# schema = StructType([\n",
    "#     StructField(\"article_id\", StringType(), True),\n",
    "#     StructField(\"title\", StringType(), True),  \n",
    "#     StructField(\"link\", StringType(), True),\n",
    "#     StructField(\"keywords\", StringType(), True),\n",
    "#     StructField(\"creator\", StringType(), True),\n",
    "#     StructField(\"video_url\", StringType(), True),\n",
    "#     StructField(\"description\", StringType(), True),\n",
    "#     StructField(\"content\", StringType(), True),\n",
    "#     StructField(\"pubDate\", StringType(), True),\n",
    "#     StructField(\"pubDateTZ\", StringType(), True),\n",
    "#     StructField(\"image_url\", StringType(), True),\n",
    "#     StructField(\"source_id\", StringType(), True),\n",
    "#     StructField(\"source_priority\", StringType(), True),\n",
    "#     StructField(\"source_name\", StringType(), True),\n",
    "#     StructField(\"source_url\", StringType(), True),\n",
    "#     StructField(\"source_icon\", StringType(), True),\n",
    "#     StructField(\"language\", StringType(), True),\n",
    "#     StructField(\"country\", StringType(), True),\n",
    "#     StructField(\"category\", StringType(), True),\n",
    "#     StructField(\"ai_tag\", StringType(), True),\n",
    "#     StructField(\"sentiment\", StringType(), True),\n",
    "#     StructField(\"sentiment_stats\", StringType(), True),\n",
    "#     StructField(\"ai_region\", StringType(), True),\n",
    "#     StructField(\"ai_org\", StringType(), True),\n",
    "#     StructField(\"duplicate\", BooleanType(), True)\n",
    "# ])\n",
    "\n",
    "# df = spark.createDataFrame(news_list, schema=schema)\n",
    "# df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5f5c6-7529-4022-b93d-c3f64e1148cb",
   "metadata": {},
   "source": [
    "## Kafka Producer (news_io_producer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6652785-fa32-49ea-9f50-4294ae67471a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnewsdataapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NewsDataApiClient\n\u001b[1;32m      6\u001b[0m api \u001b[38;5;241m=\u001b[39m NewsDataApiClient(apikey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpub_74815e364b4e931611590c50e5c72985ca80a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m producer \u001b[38;5;241m=\u001b[39m \u001b[43mKafkaProducer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbootstrap_servers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost:9092\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_serializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfetch_and_publish_news\u001b[39m():\n\u001b[1;32m     14\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/producer/kafka.py:406\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    403\u001b[0m reporters \u001b[38;5;241m=\u001b[39m [reporter() \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_reporters\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[0;32m--> 406\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkafka_client\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_group_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproducer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwakeup_timeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_block_ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# Get auto-discovered / normalized version from client\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/client_async.py:262\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Check Broker Version if not set explicitly\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m BROKER_API_VERSIONS:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_versions \u001b[38;5;241m=\u001b[39m BROKER_API_VERSIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/client_async.py:1064\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[0;34m(self, node_id, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNodeNotReadyError(node_id)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "# from kafka import KafkaProducer\n",
    "# import json\n",
    "# import time\n",
    "# from newsdataapi import NewsDataApiClient\n",
    "\n",
    "# api = NewsDataApiClient(apikey=\"pub_74815e364b4e931611590c50e5c72985ca80a\")\n",
    "\n",
    "# producer = KafkaProducer(\n",
    "#     bootstrap_servers='localhost:9092',\n",
    "#     value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "# )\n",
    "\n",
    "# def fetch_and_publish_news():\n",
    "#     page = None\n",
    "#     while True:\n",
    "#         response = api.news_api(\n",
    "#             category='crime',\n",
    "#             language='en',\n",
    "#             page=page\n",
    "#         )\n",
    "#         news_list = response.get('results', [])\n",
    "#         for news in news_list:\n",
    "#             # Clean and transform fields\n",
    "#             new_news = {\n",
    "#                 \"title\": news.get(\"title\"),\n",
    "#                 \"content\": news.get(\"description\"),\n",
    "#                 \"pubDate\": news.get(\"pubDate\"),\n",
    "#                 \"link\": news.get(\"link\"),\n",
    "#                 \"category\": news.get(\"category\")\n",
    "#             }\n",
    "#             producer.send('news_topic', new_news)\n",
    "#             print(f\"Sent: {new_news.get('title')}\")\n",
    "\n",
    "#         page = response.get('nextPage', 1)\n",
    "#         if not page:\n",
    "#             print(\"No more pages. Waiting for new updates...\")\n",
    "#             time.sleep(60)\n",
    "#         else:\n",
    "#             time.sleep(2)\n",
    "\n",
    "\n",
    "#     fetch_and_publish_news()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9c426-c38c-48c9-bc85-4511fdf4df29",
   "metadata": {},
   "source": [
    "## for test can be stop by set the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8edd0f-b903-4fc1-ac9d-05d027d1497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2218/2789664699.py:19: DeprecationWarning: This method is deprecated and will be removed in upcoming updates, Instead use latest_api()\n",
      "  response = api.news_api(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: Two rock legends join forces and will kick off nationwide tour in Biloxi\n",
      "Sent: Vyvamind: Examining the Rise of a Natural Adderall Alternative in the Cognitive Enhancement Market\n",
      "Sent: INTACH Surat hosts two-day symposium on World Heritage Day\n",
      "Sent: SGCCI confers lifetime achievement award on Hemant Desai\n",
      "Sent: Unlicensed dog breeder made £100,000 selling puppies online\n",
      "Sent: The legacy of two governors and their mausoleums\n",
      "Sent: CHAGEE Rings the Opening Bell on The Nasdaq\n",
      "Sent: ITS Logistics Distribution + Fulfillment Q2 Index: Conflicting Outlooks Highlight Uncertainty in Distribution and Fulfillment Space\n",
      "Sent: Toll Brothers Announces New Luxury Home Community Coming Soon to Leander, Texas\n",
      "Sent: Man stopped as part of PSNI anti-speeding campaign charged with importing drugs with intent to supply\n",
      "Sent: Armed police stormed home due to 'risk to life' fears - but didn't find what they expected\n",
      "Sent: Gray Promotes Dana Neves to Senior Managing Vice President\n",
      "Reached limit of 12 messages. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# from kafka import KafkaProducer\n",
    "# import json\n",
    "# import time\n",
    "# from newsdataapi import NewsDataApiClient\n",
    "\n",
    "# api = NewsDataApiClient(apikey=\"pub_74815e364b4e931611590c50e5c72985ca80a\")\n",
    "\n",
    "# producer = KafkaProducer(\n",
    "#     bootstrap_servers='localhost:9092',\n",
    "#     value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "# )\n",
    "\n",
    "\n",
    "# def fetch_and_publish_news(max_messages=None):\n",
    "#     page = None\n",
    "#     message_count = 0\n",
    "\n",
    "#     while True:\n",
    "#         response = api.news_api(\n",
    "#             category='crime',\n",
    "#             language='en',\n",
    "#             page=page\n",
    "#         )\n",
    "#         news_list = response.get('results', [])\n",
    "#         for news in news_list:\n",
    "#             new_news = {\n",
    "#                 \"title\": news.get(\"title\"),\n",
    "#                 \"content\": news.get(\"description\"),\n",
    "#                 \"pubDate\": news.get(\"pubDate\"),\n",
    "#                 \"link\": news.get(\"link\"),\n",
    "#                 \"category\": news.get(\"category\")\n",
    "#             }\n",
    "#             producer.send('news_io_topic', new_news)\n",
    "#             print(f\"Sent: {new_news.get('title')}\")\n",
    "#             message_count += 1\n",
    "\n",
    "#             # Check if we've reached max_messages (if set)\n",
    "#             if max_messages and message_count >= max_messages:\n",
    "#                 print(f\"Reached limit of {max_messages} messages. Stopping.\")\n",
    "#                 producer.flush()\n",
    "#                 return\n",
    "\n",
    "#         page = response.get('nextPage', None)\n",
    "#         if not page:\n",
    "#             print(\"No more pages. Waiting for new updates...\")\n",
    "#             time.sleep(60)\n",
    "#         else:\n",
    "#             time.sleep(2)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     fetch_and_publish_news(max_messages=12)  # Set limit here (e.g., 20)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d27e3a1-e446-4c8a-b57a-59ce6343eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2218/426894422.py:26: DeprecationWarning: This method is deprecated and will be removed in upcoming updates, Instead use latest_api()\n",
      "  response = self.api_client.news_api(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: Two rock legends join forces and will kick off nationwide tour in Biloxi\n",
      "Sent: Vyvamind: Examining the Rise of a Natural Adderall Alternative in the Cognitive Enhancement Market\n",
      "Sent: INTACH Surat hosts two-day symposium on World Heritage Day\n",
      "Sent: SGCCI confers lifetime achievement award on Hemant Desai\n",
      "Sent: Unlicensed dog breeder made £100,000 selling puppies online\n",
      "Sent: The legacy of two governors and their mausoleums\n",
      "Sent: CHAGEE Rings the Opening Bell on The Nasdaq\n",
      "Sent: ITS Logistics Distribution + Fulfillment Q2 Index: Conflicting Outlooks Highlight Uncertainty in Distribution and Fulfillment Space\n",
      "Sent: Toll Brothers Announces New Luxury Home Community Coming Soon to Leander, Texas\n",
      "Sent: Man stopped as part of PSNI anti-speeding campaign charged with importing drugs with intent to supply\n",
      "Sent: Armed police stormed home due to 'risk to life' fears - but didn't find what they expected\n",
      "Sent: Gray Promotes Dana Neves to Senior Managing Vice President\n",
      "Reached limit of 12 messages. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "from newsdataapi import NewsDataApiClient\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class NewsKafkaProducer:\n",
    "    def __init__(self, kafka_bootstrap_servers, kafka_topic, news_api_key):\n",
    "        # Initialize Kafka producer\n",
    "        self.producer = KafkaProducer(\n",
    "            bootstrap_servers=kafka_bootstrap_servers,\n",
    "            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "        )\n",
    "\n",
    "        # Initialize NewsData API client\n",
    "        self.api_client = NewsDataApiClient(apikey=news_api_key)\n",
    "\n",
    "        # Kafka topic\n",
    "        self.topic = kafka_topic\n",
    "\n",
    "    def fetch_and_publish_news(self, category='crime', language='en', max_messages=None):\n",
    "        page = None\n",
    "        message_count = 0\n",
    "\n",
    "        while True:\n",
    "            response = self.api_client.news_api(\n",
    "                category=category,\n",
    "                language=language,\n",
    "                page=page\n",
    "            )\n",
    "\n",
    "            news_list = response.get('results', [])\n",
    "\n",
    "            if not news_list:\n",
    "                print(\"No news found. Waiting for updates...\")\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "\n",
    "            for news in news_list:\n",
    "                news_data = {\n",
    "                    \"title\": news.get(\"title\"),\n",
    "                    \"content\": news.get(\"description\"),\n",
    "                    \"pubDate\": news.get(\"pubDate\"),\n",
    "                    \"link\": news.get(\"link\"),\n",
    "                    \"category\": news.get(\"category\")\n",
    "                }\n",
    "\n",
    "                self.send_to_kafka(news_data)\n",
    "                message_count += 1\n",
    "\n",
    "                if max_messages and message_count >= max_messages:\n",
    "                    print(f\"Reached limit of {max_messages} messages. Stopping.\")\n",
    "                    self.producer.flush()\n",
    "                    return\n",
    "\n",
    "            page = response.get('nextPage', None)\n",
    "\n",
    "            if not page:\n",
    "                print(\"No more pages. Waiting for new updates...\")\n",
    "                time.sleep(60)\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "\n",
    "    def send_to_kafka(self, message):\n",
    "        \"\"\"Send message to Kafka topic.\"\"\"\n",
    "        self.producer.send(self.topic, message)\n",
    "        print(f\"Sent: {message.get('title')}\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Flush and close the Kafka producer.\"\"\"\n",
    "        self.producer.flush()\n",
    "        self.producer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kafka_servers = 'localhost:9092'\n",
    "    kafka_topic = 'news_io_topic'\n",
    "    news_api_key = 'pub_74815e364b4e931611590c50e5c72985ca80a'\n",
    "\n",
    "    producer = NewsKafkaProducer(\n",
    "        kafka_bootstrap_servers=kafka_servers,\n",
    "        kafka_topic=kafka_topic,\n",
    "        news_api_key=news_api_key\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        producer.fetch_and_publish_news(max_messages=12)\n",
    "    finally:\n",
    "        producer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29ff3cc-b267-466e-a0d1-425b06f36419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consuming messages...\n",
      "Saved: Two rock legends join forces and will kick off nationwide to\n",
      "Saved: Vyvamind: Examining the Rise of a Natural Adderall Alternati\n",
      "Saved: INTACH Surat hosts two-day symposium on World Heritage Day\n",
      "Saved: SGCCI confers lifetime achievement award on Hemant Desai\n",
      "Saved: Unlicensed dog breeder made £100,000 selling puppies online\n",
      "Saved: The legacy of two governors and their mausoleums\n",
      "Saved: CHAGEE Rings the Opening Bell on The Nasdaq\n",
      "Saved: ITS Logistics Distribution + Fulfillment Q2 Index: Conflicti\n",
      "Saved: Toll Brothers Announces New Luxury Home Community Coming Soo\n",
      "Saved: Man stopped as part of PSNI anti-speeding campaign charged w\n",
      "Saved: Armed police stormed home due to 'risk to life' fears - but \n",
      "Saved: Gray Promotes Dana Neves to Senior Managing Vice President\n",
      "Saved: Two rock legends join forces and will kick off nationwide to\n",
      "Saved: Vyvamind: Examining the Rise of a Natural Adderall Alternati\n",
      "Saved: INTACH Surat hosts two-day symposium on World Heritage Day\n",
      "Saved: SGCCI confers lifetime achievement award on Hemant Desai\n",
      "Saved: Unlicensed dog breeder made £100,000 selling puppies online\n",
      "Saved: The legacy of two governors and their mausoleums\n",
      "Saved: CHAGEE Rings the Opening Bell on The Nasdaq\n",
      "Saved: ITS Logistics Distribution + Fulfillment Q2 Index: Conflicti\n",
      "Saved: Toll Brothers Announces New Luxury Home Community Coming Soo\n",
      "Saved: Man stopped as part of PSNI anti-speeding campaign charged w\n",
      "Saved: Armed police stormed home due to 'risk to life' fears - but \n",
      "Saved: Gray Promotes Dana Neves to Senior Managing Vice President\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m consumer \u001b[38;5;241m=\u001b[39m ArticleConsumer()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsume_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mArticleConsumer.consume_and_save\u001b[0;34m(self, output_file)\u001b[0m\n\u001b[1;32m     24\u001b[0m writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(csvfile, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[1;32m     25\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsumer:\n\u001b[1;32m     28\u001b[0m     article \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     29\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow(article)\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/consumer/group.py:1172\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/consumer/group.py:1144\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1143\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1144\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1150\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/consumer/group.py:679\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    677\u001b[0m inner_timeout_ms \u001b[38;5;241m=\u001b[39m timeout_ms_fn(timeout_ms, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m--> 679\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/consumer/group.py:726\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(futures):\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_to_next_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/client_async.py:683\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    676\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    677\u001b[0m             user_timeout_ms,\n\u001b[1;32m    678\u001b[0m             metadata_timeout_ms,\n\u001b[1;32m    679\u001b[0m             idle_connection_timeout_ms,\n\u001b[1;32m    680\u001b[0m             request_timeout_ms)\n\u001b[1;32m    681\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    687\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/client_async.py:726\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    725\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 726\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import csv\n",
    "\n",
    "class ArticleConsumer:\n",
    "    def __init__(self, kafka_server='localhost:9092', topic='news_io_topic'):\n",
    "        self.consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=kafka_server,\n",
    "            auto_offset_reset='earliest',\n",
    "            # auto_offset_reset='latest',\n",
    "            enable_auto_commit=True,\n",
    "            value_deserializer=lambda v: json.loads(v.decode('utf-8'))\n",
    "        )\n",
    "        \n",
    "# # Subscribe to a specific topic\n",
    "# consumer.subscribe(topics=['my-topic'])\n",
    "    \n",
    "    def consume_and_save(self, output_file='kafka_new_io_articles_output.csv'):\n",
    "        print(\"Consuming messages...\")\n",
    "        fieldnames = ['title', 'content', 'pubDate', 'link','category']  \n",
    "\n",
    "        with open(output_file, 'w', encoding='utf-8-sig', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for message in self.consumer:\n",
    "                article = message.value\n",
    "                writer.writerow(article)\n",
    "                print(f\"Saved: {article['title'][:60]}\") \n",
    "\n",
    "# Example usage:\n",
    "consumer = ArticleConsumer()\n",
    "consumer.consume_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d458efe0-361d-4c3a-b8f7-46242c76678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885751e-ec81-4851-a3b6-3bc39ecc065c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
